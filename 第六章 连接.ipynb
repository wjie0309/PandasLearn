{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 连接\n",
    "\n",
    "### 连接的基本概念\n",
    "\n",
    "连接, 是将两张相关的表中不同数据进行整合的方式. 连接常见的模式有四种: 分为左连接 `left` 、右连接 `right` 、内连接 `inner` 、外连接 `outer`. 连接时有一个很重要的参数是连接的键, 表示连接时参照的数据列, 一般使用 `on` 进行定义.\n",
    "\n",
    "它们的差别主要体现在连接时选取的基准以及保存数据的标准上.\n",
    "\n",
    "![](https://s1.vika.cn/space/2022/09/13/a7c4516ebb1e4b24b2ff609eca41423b)\n",
    "\n",
    "- 左连接以左表的数据为准, 不属于左表的数据则不会出现.\n",
    "- 右连接以右表的数据为准, 不属于右表的数据则不会出现.\n",
    "- 内连接则是选取两表中都存在的数据.\n",
    "- 外连接选取两表里的所有数据, 因此又称为 全连接.\n",
    "\n",
    "### 值连接: merge\n",
    "\n",
    "为了实现上图中提到的根据列表数据中的某一列的值来进行连接, 可以使用 `merge` 函数进行操作. \n",
    "\n",
    "- 在使用时常见的参数有:\n",
    "\n",
    "\t- on: 参考的列名\n",
    "\t- how: 定义连接的方式\n",
    "\t- left_on/right_on: 在两个表想要合并的参考标准列名不同时\n",
    "\t- suffixes: 在出现了重复的列名但是表示不同意思的时候, 可以使用 suffixes 参数来给两列重命名\n",
    "\t- validate: 检测数据的唯一性模式, 有 1:1, 1:m, m:1 连接模式.\n",
    "\n",
    "### 索引连接: join\n",
    "\n",
    "索引连接即为将索引视为列, 这种情况使用 join 函数进行实现.\n",
    "\n",
    "join 函数具有和 merge 函数相似的两个参数: on, how, 除此之外还有和 suffixes 相似的 lsuffix, rsuffix. 使用这些参数来定义 join 函数可以让其与 merge 函数起到相似的作用.\n",
    "\n",
    "### 方向连接\n",
    "\n",
    "#### concat\n",
    "\n",
    "前文提到过的关系型连接是根据数据的内容和相关性进行连接, 除此之外, 有时候我们单纯地希望两个数据进行横向或者纵向的拼接. 这个时候就可以使用 concat 函数.\n",
    "\n",
    "默认 axis=0, 为纵向拼接, 1 为横向拼接. 除此之外, concat 的默认连接模式为外连接, 但可以通过 join 参数来调整连接模式.\n",
    "\n",
    "当确认要使用多表直接的方向合并时, 尤其是横向的合并, 可以先用 `reset_index` 方法恢复默认整数索引再进行合并, 防止出现由索引的误对齐和重复索引的笛卡尔积带来的错误结果.\n",
    "\n",
    "keys 参数可以在连接后仍然显示数据的来源, 通过多重索引的展示形式将其来源的表格显示出来.\n",
    "\n",
    "#### append, assign\n",
    "\n",
    "如果想要把一个序列追加到表的行末或者列末, 则可以分别使用 `append` 和 `assign` 方法.\n",
    "\n",
    "使用 assign 和直接使用 `df[Name]` 的方式去定义列的区别是, 这样会只返回一个临时脚本, 而不会影响原数据.\n",
    "\n",
    "### 类连接方法\n",
    "\n",
    "#### compare\n",
    "\n",
    "它能够比较两个表或者序列的不同处并将其汇总展示\n",
    "\n",
    "#### combine\n",
    "\n",
    "让两张表按照一定的规则进行组合, 在进行规则比较时会自动进行列索引的对齐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、练习\n",
    "### Ex1：美国疫情数据集\n",
    "\n",
    "现有美国4月12日至11月16日的疫情报表（在`/data/us_report`文件夹下），请将`New York`的`Confirmed, Deaths, Recovered, Active`合并为一张表，索引为按如下方法生成的日期字符串序列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['04-12-2020', '04-13-2020', '04-14-2020', '04-15-2020', '04-16-2020']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "date = pd.date_range('20200412', '20201116').to_series()\n",
    "date = date.dt.month.astype('string').str.zfill(2) +'-'+ date.dt.day.astype('string').str.zfill(2) +'-'+ '2020'\n",
    "date = date.tolist()\n",
    "date[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>04-12-2020</th>\n",
       "      <td>189033</td>\n",
       "      <td>9385</td>\n",
       "      <td>23887.0</td>\n",
       "      <td>179648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04-13-2020</th>\n",
       "      <td>195749</td>\n",
       "      <td>10058</td>\n",
       "      <td>23887.0</td>\n",
       "      <td>185691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04-14-2020</th>\n",
       "      <td>203020</td>\n",
       "      <td>10842</td>\n",
       "      <td>23887.0</td>\n",
       "      <td>192178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04-15-2020</th>\n",
       "      <td>214454</td>\n",
       "      <td>11617</td>\n",
       "      <td>23887.0</td>\n",
       "      <td>202837.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04-16-2020</th>\n",
       "      <td>223691</td>\n",
       "      <td>14832</td>\n",
       "      <td>23887.0</td>\n",
       "      <td>208859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-12-2020</th>\n",
       "      <td>545762</td>\n",
       "      <td>33975</td>\n",
       "      <td>81198.0</td>\n",
       "      <td>430589.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-13-2020</th>\n",
       "      <td>551163</td>\n",
       "      <td>33993</td>\n",
       "      <td>81390.0</td>\n",
       "      <td>435780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-14-2020</th>\n",
       "      <td>556551</td>\n",
       "      <td>34010</td>\n",
       "      <td>81585.0</td>\n",
       "      <td>440956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-15-2020</th>\n",
       "      <td>560200</td>\n",
       "      <td>34032</td>\n",
       "      <td>81788.0</td>\n",
       "      <td>444380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-16-2020</th>\n",
       "      <td>563690</td>\n",
       "      <td>34054</td>\n",
       "      <td>81908.0</td>\n",
       "      <td>447728.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Confirmed Deaths Recovered    Active\n",
       "04-12-2020    189033   9385   23887.0    179648\n",
       "04-13-2020    195749  10058   23887.0  185691.0\n",
       "04-14-2020    203020  10842   23887.0  192178.0\n",
       "04-15-2020    214454  11617   23887.0  202837.0\n",
       "04-16-2020    223691  14832   23887.0  208859.0\n",
       "...              ...    ...       ...       ...\n",
       "11-12-2020    545762  33975   81198.0  430589.0\n",
       "11-13-2020    551163  33993   81390.0  435780.0\n",
       "11-14-2020    556551  34010   81585.0  440956.0\n",
       "11-15-2020    560200  34032   81788.0  444380.0\n",
       "11-16-2020    563690  34054   81908.0  447728.0\n",
       "\n",
       "[219 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for i in date:\n",
    "    df = pd.read_csv('./data/us_report/' + i + '.csv', index_col='Province_State')\n",
    "    res.append(df.loc['New York', ['Confirmed', 'Deaths', 'Recovered', 'Active']].to_frame().T)\n",
    "    \n",
    "res1 = pd.concat(res)\n",
    "res1.index= date\n",
    "res1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex2：实现join函数\n",
    "\n",
    "请实现带有`how`参数的`join`函数\n",
    "\n",
    "* 假设连接的两表无公共列\n",
    "* 调用方式为 `join(df1, df2, how=\"left\")`\n",
    "* 给出测试样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(df1, df2, how='left'):\n",
    "    res_col = df1.columns.tolist() +  df2.columns.tolist()\n",
    "    dup = df1.index.unique().intersection(df2.index.unique())\n",
    "    res_df = pd.DataFrame(columns = res_col)\n",
    "    for label in dup:\n",
    "        cartesian = [list(i)+list(j) for i in df1.loc[label].values.reshape(-1,1) for j in df2.loc[label].values.reshape(-1,1)]\n",
    "        dup_df = pd.DataFrame(cartesian, index = [label]*len(cartesian), columns = res_col)\n",
    "        res_df = pd.concat([res_df,dup_df])\n",
    "    if how in ['left', 'outer']:\n",
    "        for label in df1.index.unique().difference(dup):\n",
    "            if isinstance(df1.loc[label], pd.DataFrame):\n",
    "                cat = [list(i)+[np.nan]*df2.shape[1] for i in df1.loc[label].values]\n",
    "            else:\n",
    "                cat = [list(i)+[np.nan]*df2.shape[1] for i in df1.loc[label].to_frame().values]\n",
    "            dup_df = pd.DataFrame(cat, index = [label]*len(cat), columns = res_col)\n",
    "            res_df = pd.concat([res_df,dup_df])\n",
    "    if how in ['right', 'outer']:\n",
    "        for label in df2.index.unique().difference(dup):\n",
    "            if isinstance(df2.loc[label], pd.DataFrame):\n",
    "                cat = [[np.nan]+list(i)*df1.shape[1] for i in df2.loc[label].values]\n",
    "            else:\n",
    "                cat = [[np.nan]+list(i)*df1.shape[1] for i in df2.loc[label].to_frame().values]\n",
    "            dup_df = pd.DataFrame(cat, index = [label]*len(cat), columns = res_col)\n",
    "            res_df = pd.concat([res_df,dup_df])\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1\n",
       "A     1\n",
       "A     2\n",
       "B     3\n",
       "C     4\n",
       "D     5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'col1':[1,2,3,4,5]}, index=list('AABCD'))\n",
    "df1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
